{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "from textstat.textstat import textstat\n",
    "from textblob import TextBlob\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class PorterTokenizer(object):\n",
    "    \"\"\"Custom PorterTokenizer for TfidfVectorizer\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "        return [self.stemmer.stem(t) for t in word_tokenize(doc.translate(translate_table))]\n",
    "\n",
    "class Vectorizer(object):\n",
    "    \"\"\"Vecotizer wrapper for sklearn TfidfVectorizer.\n",
    "\n",
    "    Allows passing of custom tokenizer\n",
    "\n",
    "    TODO: add more custom tokenizers\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 tokenizer=None,\n",
    "                 encoding='utf-8',\n",
    "                 stop_words='english',\n",
    "                 min_df=1,\n",
    "                 ngram_range=None):\n",
    "        self.tokenizers = {'porter': PorterTokenizer()}\n",
    "        self.vectorizer = TfidfVectorizer(tokenizer=self.tokenizers[tokenizer],\n",
    "                                          encoding=encoding,\n",
    "                                          stop_words=stop_words,\n",
    "                                          min_df=min_df,\n",
    "                                          ngram_range=ngram_range)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.vectorizer.fit_transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.vectorizer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "def remove_handles(content):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)\",\" \",content).split())\n",
    "\n",
    "def count_handles(content):\n",
    "    return len(re.findall(\"(@[A-Za-z0-9]+)\",content))\n",
    "\n",
    "def bool_handles(content):\n",
    "    match = re.search(\"(@[A-Za-z0-9]+)\", content)\n",
    "    if match:\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def count_hashtags(content):\n",
    "    return len(re.findall(\"(#[A-Za-z0-9]+)\",content))\n",
    "\n",
    "def bool_hashtags(content):\n",
    "    match = re.search(\"(#[A-Za-z0-9]+)\", content)\n",
    "    if match:\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def is_retweet(content):\n",
    "    return int(\"RT \" in content)\n",
    "\n",
    "def has_url(content):\n",
    "    return int(\"https://\" in content or \"http://\" in content)\n",
    "\n",
    "def build_POS_list(content):\n",
    "    content = content.decode('latin-1')\n",
    "    return ' '.join([item[1] for item in pos_tag(word_tokenize(content))])\n",
    "\n",
    "def create_features(df, feature_cols, vec, pos_vectorizer):\n",
    "    features = df[feature_cols].values\n",
    "    n_gram_vector = vec.vectorizer.transform(df['tweet_no_handle'].values)\n",
    "    pos_ngram_vector = pos_vectorizer.transform(df['pos_tags'].values)\n",
    "    feature_vector = np.concatenate((n_gram_vector.todense(), features, pos_ngram_vector.todense()), axis=1)\n",
    "    \n",
    "    return feature_vector\n",
    "\n",
    "# Model specifications for tweets\n",
    "def test_model(base_model, param_grid):\n",
    "    grid_clf = GridSearchCV(base_model, param_grid, cv=5)\n",
    "    grid_clf.fit(train_features, y_train)\n",
    "    preds = grid_clf.predict(test_features)\n",
    "    print(classification_report(y_test, preds))\n",
    "    return grid_clf\n",
    "\n",
    "def top_words(clf, label, top):\n",
    "    for i in clf.best_estimator_.coef_[label, :].argsort()[::-1][:top]:\n",
    "        top_words = (i, clf.best_estimator_.coef_[0, i], vec.vectorizer.get_feature_names()[i])\n",
    "        print \"{}\".format(top_words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_only_df = pd.read_csv('data/labels_and_text_only.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Features/ Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_only_df['tweet_no_handle'] = text_only_df['tweet_text'].apply(remove_handles)\n",
    "text_only_df['reading_ease'] = text_only_df['tweet_no_handle'].apply(textstat.flesch_reading_ease)\n",
    "text_only_df['reading_grade'] = text_only_df['tweet_no_handle'].apply(textstat.flesch_kincaid_grade)\n",
    "text_only_df['sentiment'] = text_only_df['tweet_no_handle'].map(lambda x: TextBlob(x.decode('latin-1')).polarity)\n",
    "text_only_df['subjectivity'] = text_only_df['tweet_no_handle'].map(lambda x: TextBlob(x.decode('latin-1')).subjectivity)\n",
    "text_only_df['mentions_count'] = text_only_df['tweet_text'].apply(count_handles)\n",
    "text_only_df['mentions_bool'] = text_only_df['tweet_text'].apply(bool_handles)\n",
    "text_only_df['hashtag_count'] = text_only_df['tweet_text'].apply(count_hashtags)\n",
    "text_only_df['hashtag_bool'] = text_only_df['tweet_text'].apply(bool_hashtags)\n",
    "text_only_df['has_url'] = text_only_df['tweet_text'].apply(is_retweet)\n",
    "text_only_df['tweet_length'] = text_only_df['tweet_no_handle'].apply(len)\n",
    "text_only_df['word_count'] = text_only_df['tweet_no_handle'].apply(textstat.lexicon_count)\n",
    "text_only_df['syllable_count'] = text_only_df['tweet_no_handle'].apply(textstat.syllable_count)\n",
    "text_only_df['pos_tags'] = text_only_df['tweet_no_handle'].apply(build_POS_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Determine logisitic model with x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = text_only_df.drop(['tweet_text', 'labels'], axis=1)\n",
    "y = text_only_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vec = Vectorizer(tokenizer='porter',\n",
    "                   encoding='latin-1',\n",
    "                   min_df=5,\n",
    "                   ngram_range=(1,3))\n",
    "pos_vectorizer = CountVectorizer(ngram_range=(1,3), min_df=5)\n",
    "text_only_df['pos_tag_ngrams'] = pos_vectorizer.fit_transform(text_only_df['pos_tags']).todense().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#text_only_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [u'reading_ease',\n",
    "                u'reading_grade', \n",
    "                u'sentiment', \n",
    "                u'subjectivity', \n",
    "                u'mentions_count',\n",
    "                u'mentions_bool', \n",
    "                u'hashtag_count', \n",
    "                u'hashtag_bool', \n",
    "                u'has_url',\n",
    "                u'tweet_length', \n",
    "                u'word_count', \n",
    "                u'syllable_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = X_train['tweet_no_handle'] \n",
    "vec.fit(train_text);\n",
    "pos_vectorizer.fit(X_train['pos_tags'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_features = create_features(X_train, feature_cols, vec, pos_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_features = create_features(X_test, feature_cols, vec, pos_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 8149)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(class_weight='balanced', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000]}\n",
    "]\n",
    "\n",
    "log_r = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         hate       0.49      0.52      0.50       240\n",
      "not offensive       0.85      0.90      0.87       727\n",
      "    offensive       0.67      0.59      0.63       484\n",
      "\n",
      "  avg / total       0.73      0.73      0.73      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_model = test_model(log_r, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nigger\n",
      "faggot\n",
      "kill\n",
      "queer\n",
      "fag\n"
     ]
    }
   ],
   "source": [
    "twitter_top_words = top_words(my_model, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate-speech-classifier.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(my_model, 'model/hate-speech-classifier.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
