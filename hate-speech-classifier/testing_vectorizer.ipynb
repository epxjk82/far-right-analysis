{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import src.vectorizer as vectorizer\n",
    "import src.preprocessing as preprocessing\n",
    "import re\n",
    "from textstat.textstat import textstat\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "import string\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_only_df = pd.read_csv('data/labels_and_text_only.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_handles(content):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)\",\" \",content).split())\n",
    "\n",
    "def count_handles(content):\n",
    "    return len(re.findall(\"(@[A-Za-z0-9]+)\",content))\n",
    "\n",
    "def bool_handles(content):\n",
    "    match = re.search(\"(@[A-Za-z0-9]+)\", content)\n",
    "    if match:\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def count_hashtags(content):\n",
    "    return len(re.findall(\"(#[A-Za-z0-9]+)\",content))\n",
    "\n",
    "def bool_hashtags(content):\n",
    "    match = re.search(\"(#[A-Za-z0-9]+)\", content)\n",
    "    if match:\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def is_retweet(content):\n",
    "    return int(\"RT \" in content)\n",
    "\n",
    "def has_url(content):\n",
    "    return int(\"https://\" in content or \"http://\" in content)\n",
    "\n",
    "def build_POS_list(content):\n",
    "    content = content.decode('latin-1')\n",
    "    return ' '.join([item[1] for item in pos_tag(word_tokenize(content))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_only_df['tweet_no_handle'] = text_only_df['tweet_text'].apply(remove_handles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Reading Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_only_df['reading_ease'] = text_only_df['tweet_no_handle'].apply(textstat.flesch_reading_ease)\n",
    "text_only_df['reading_grade'] = text_only_df['tweet_no_handle'].apply(textstat.flesch_kincaid_grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_only_df['sentiment'] = text_only_df['tweet_no_handle'].map(lambda x: TextBlob(x.decode('latin-1')).polarity)\n",
    "text_only_df['subjectivity'] = text_only_df['tweet_no_handle'].map(lambda x: TextBlob(x.decode('latin-1')).subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add More Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_only_df['mentions_count'] = text_only_df['tweet_text'].apply(count_handles)\n",
    "text_only_df['mentions_bool'] = text_only_df['tweet_text'].apply(bool_handles)\n",
    "text_only_df['hashtag_count'] = text_only_df['tweet_text'].apply(count_hashtags)\n",
    "text_only_df['hashtag_bool'] = text_only_df['tweet_text'].apply(bool_hashtags)\n",
    "text_only_df['has_url'] = text_only_df['tweet_text'].apply(is_retweet)\n",
    "text_only_df['tweet_length'] = text_only_df['tweet_no_handle'].apply(len)\n",
    "text_only_df['word_count'] = text_only_df['tweet_no_handle'].apply(textstat.lexicon_count)\n",
    "text_only_df['syllable_count'] = text_only_df['tweet_no_handle'].apply(textstat.syllable_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_only_df['pos_tags'] = text_only_df['tweet_no_handle'].apply(build_POS_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = text_only_df.drop(['tweet_text', 'labels'], axis=1)\n",
    "y = text_only_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = vectorizer.Vectorizer(tokenizer='porter',\n",
    "                   encoding='latin-1',\n",
    "                   min_df=5,\n",
    "                   ngram_range=(1,3))\n",
    "pos_vectorizer = CountVectorizer(ngram_range=(1,3), min_df=5)\n",
    "text_only_df['pos_tag_ngrams'] = pos_vectorizer.fit_transform(text_only_df['pos_tags']).todense().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'labels', u'tweet_text', u'tweet_no_handle', u'reading_ease',\n",
       "       u'reading_grade', u'sentiment', u'subjectivity', u'mentions_count',\n",
       "       u'mentions_bool', u'hashtag_count', u'hashtag_bool', u'has_url',\n",
       "       u'tweet_length', u'word_count', u'syllable_count', u'pos_tags',\n",
       "       u'pos_tag_ngrams'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(df, feature_cols, vec):\n",
    "    features = df[feature_cols].values\n",
    "    n_gram_vector = vec.vectorizer.transform(df['tweet_no_handle'].values)\n",
    "    feature_vector = np.concatenate((n_gram_vector.todense(), features, df['pos_tag_ngrams'].tolist()), axis=1)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [u'reading_ease',\n",
    "                u'reading_grade', \n",
    "                u'sentiment', \n",
    "                u'subjectivity', \n",
    "                u'mentions_count',\n",
    "                u'mentions_bool', \n",
    "                u'hashtag_count', \n",
    "                u'hashtag_bool', \n",
    "                u'has_url',\n",
    "                u'tweet_length', \n",
    "                u'word_count', \n",
    "                u'syllable_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_text = X_train['tweet_no_handle'] \n",
    "vec.fit(train_text);\n",
    "\n",
    "pos_vectorizer.fit(text_only_df['pos_tags']).todense().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = create_features(X_train, feature_cols, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = create_features(X_test, feature_cols, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 13025)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000]}\n",
    "]\n",
    "\n",
    "log_r = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model(base_model, param_grid):\n",
    "    grid_clf = GridSearchCV(base_model, param_grid, cv=5)\n",
    "    grid_clf.fit(train_features, y_train)\n",
    "    preds = grid_clf.predict(test_features)\n",
    "    print(classification_report(y_test, preds))\n",
    "    return grid_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_words(clf, label, top):\n",
    "    for i in clf.best_estimator_.coef_[label, :].argsort()[::-1][:top]:\n",
    "        top_words = (i, clf.best_estimator_.coef_[0, i], vec.vectorizer.get_feature_names()[i])\n",
    "        print \"{}\".format(top_words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         hate       0.48      0.50      0.49       240\n",
      "not offensive       0.84      0.88      0.86       727\n",
      "    offensive       0.65      0.60      0.62       484\n",
      "\n",
      "  avg / total       0.72      0.72      0.72      1451\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [1, 10, 100, 1000]}], pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(log_r, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[10, 25, 50, 100]}\n",
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_forest = test_model(forest, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_only_df.sentiment.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x='labels', data=text_only_df, y='sentiment', jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=text_only_df, x='labels', y='sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_only_df[(text_only_df['labels']=='hate') & (text_only_df.sentiment > 0.8)].tweet_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_only_df.subjectivity.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x='labels', data=text_only_df, y='subjectivity', jitter=True, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=text_only_df, x='labels', y='subjectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_only_df.reading_ease.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_only_df.reading_grade.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(data=text_only_df, x='labels', y='reading_ease', jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(data=text_only_df, x='labels', y='reading_grade', jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pointplot(x='labels', y='reading_ease', data=text_only_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pointplot(x='labels', y='reading_grade', data=text_only_df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
